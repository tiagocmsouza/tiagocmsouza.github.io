---
title: "Currency Beta's with respect to the USD"
author: "Tiago Souza"
date: "2023-01-20"
categories: [econometrics, python]
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import eurostat
from datetime import datetime
import statsmodels.api as sm
```

This post is to check whether noise in daily data constitutes a problem to the estimation of currenies' sensitivity with respect to the $USD$, a common exercise done in financial markets.

Assume that there exists a relationship of currency $x_{t}$  with repect to the $USD$ on a dily basis:

$$
\begin{aligned}
x_{t} = \alpha_{x} + \beta_{x} USD_{t} + \varepsilon_{t},
\end{aligned}
$$

this equation could be estimated to find the parameters of interest (a statistical relationship, with no causal meaning!).

Remeber that the estimated coefficient is given by the simple formula:
$$
\begin{aligned}
\beta_{x} = \frac{\text{cov}(x_{t}, USD_{t})}{\text{var}(USD_{t})}.
\end{aligned}
$$

However, estimating this coefficint this way may face difficulties given the large variance of daily data.  Given that, taken the parameters as fixed, nothing prevents one from resampling the data into a different frequency:

$$
\begin{aligned}
\frac{1}{T}\sum_{t = 1}^{T}{x_{t}} & = \frac{1}{T}\sum_{t = 1}^{T}{\alpha_{x}} + \frac{1}{T}\sum_{t = 1}^{T}{\beta_{x} USD_{t}} + \frac{1}{T}\sum_{t = 1}^{T}{\varepsilon_{t}} \\
\quad{} \\
& \Rightarrow x_{T} = \alpha_{x} + \beta_{x} USD_{T} + \varepsilon_{T}
\end{aligned}
$$

Our taks now is to test whether running the regressions over different sample frequencies yields distinct estimated coefficients.

```{python}
# Download and first inspection 

df_daily = eurostat.get_data_df('ert_bil_eur_d', flags=False)

df_daily.tail(3)
```

```{python}
# Create a column with dates, select columns and filter values on interest

list_statinfo = ['AVG']
list_currency = ['AUD', 'BRL', 'CAD', 'CHF', 'CNY', 'CZK', 'GBP', 'HUF', 'IDR', 'JPY', 'MXN', 'NZD', 'PLN', 'TRY', 'USD', 'ZAR']

df_daily.rename(columns = {'currency\\TIME_PERIOD': 'currency'}, inplace = True)

df_daily = df_daily[(df_daily['statinfo'].isin(list_statinfo)) & \
     (df_daily['currency'].isin(list_currency))]

df_daily.drop(columns = ['unit', 'statinfo', 'freq'], inplace = True)

df_daily = pd.melt(df_daily, id_vars = ['currency'], var_name = 'date')

print(df_daily.tail(3))

print(df_daily.dtypes)
```

```{python}
# Put date into the correct format and place currencies in columns

df_daily['date'] = df_daily['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))

df_daily.set_index(['date', 'currency'], inplace = True)

df_daily = df_daily.unstack()

df_daily = df_daily.droplevel(level=0, axis=1)

df_daily.tail(3)
```

```{python}
# Put all currencies with respect to the USD (we downloaded currencies with respect to the EUR)

df_daily['EUR'] = 1

df_daily = df_daily.mul(1 / df_daily.loc[:,'USD'], axis = 0)

df_daily.drop('USD', axis = 1, inplace = True)

df_daily.tail(3)
```

```{python}
# Dictionary with dataframes for analysis

freq_list = ['W', 'M', 'Q']

df_dict = {'D': df_daily.pct_change().dropna()}

def resample_data(df, freq):
    
    df_resampled = df.resample(freq) \
        .last() \
        .pct_change() \
        .dropna() \
        .to_period(freq)

    return df_resampled

df_dict.update({freq: resample_data(df_daily, freq) for freq in freq_list})
```