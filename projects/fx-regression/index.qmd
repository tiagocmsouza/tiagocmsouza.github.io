---
title: "Currency Beta's with respect to the EURUSD"
author: "Tiago Souza"
date: "2023-01-20"
categories: [econometrics, python]
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import eurostat
from datetime import datetime
import statsmodels.api as sm
```

This post is to check whether noise in daily data constitutes a problem in estimating currenies' sensitivity with respect to the $EURUSD$, a common exercise done in financial markets.

Assume that there exists a relationship of currency $x_{t}$  with repect to the $EURUSD$ on a dily basis:

$$
\begin{aligned}
x_{t} = \alpha_{x} + \beta_{x} EURUSD_{t} + \varepsilon_{t},
\end{aligned}
$$

this equation could be estimated to find the parameters of interest (a statistical relationship, with no causal meaning!).

Remeber that the estimated coefficient is given by the simple formula:
$$
\begin{aligned}
\beta_{x} = \frac{\text{cov}(x_{t}, EURUSD_{t})}{\text{var}(EURUSD_{t})}.
\end{aligned}
$$

However, estimating it this way may face difficulties given the large variance of daily data. Given that, taken the parameters as fixed, nothing prevents one from resampling the data into a different frequency:

$$
\begin{aligned}
\frac{1}{T}\sum_{t = 1}^{T}{x_{t}} & = \frac{1}{T}\sum_{t = 1}^{T}{\alpha_{x}} + \frac{1}{T}\sum_{t = 1}^{T}{\beta_{x} USD_{t}} + \frac{1}{T}\sum_{t = 1}^{T}{\varepsilon_{t}} \\
\quad{} \\
& \Rightarrow x_{T} = \alpha_{x} + \beta_{x} USD_{T} + \varepsilon_{T},
\end{aligned}
$$

and estimating this instead. Our taks now is to test whether running the regressions over different sample frequencies yields distinct estimated coefficients and the extent to which using daily data represents a problem.

```{python}
# Download and first inspection of data

df_daily = eurostat.get_data_df('ert_bil_eur_d', flags=False)

df_daily.tail(3)
```

```{python}
# Create a column with dates, select columns and filter values on interest

list_statinfo = ['AVG']
list_currencies = df_daily['currency\TIME_PERIOD'].unique()
list_currencies = np.delete(list_currencies, np.where(list_currencies == 'ALL'))
# list_currency = ['AUD', 'CHF', 'CZK', 'DKK', 'GBP', 'HUF', 'JPY', 'NOK', 'NZD', 'PLN', 'TRY', 'SEK', 'USD']

df_daily = df_daily.rename(columns = {'currency\\TIME_PERIOD': 'currency'})

df_daily = df_daily[(df_daily['statinfo'].isin(list_statinfo)) &
     (df_daily['currency'].isin(list_currency))]

df_daily = df_daily.drop(columns = ['unit', 'statinfo', 'freq'])

df_daily = pd.melt(df_daily, id_vars = ['currency'], var_name = 'date')

print(df_daily.tail(3))

print(df_daily.dtypes)
```

```{python}
# Date into the correct format and place currencies in columns

df_daily['date'] = df_daily['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))

df_daily = (df_daily.set_index(['date', 'currency'])
            .unstack()
            .droplevel(level=0, axis=1))

df_daily.tail(3)
```

```{python}
# Pll currencies with respect to the USD (we downloaded currencies with respect to the EUR)

df_daily['EUR'] = 1

df_daily = (df_daily.mul(1 / df_daily.loc[:,'USD'], axis = 0)
            .drop('USD', axis = 1))

df_daily.tail(3)
```

```{python}
# Dictionary with dataframes for analysis

freq_list = ['W', 'M', 'Q']

df_dict = {'D': df_daily.pct_change().dropna()}

def resample_data(df, freq):
    
    df_resampled = (df.resample(freq)
                    .last()
                    .pct_change()
                    .dropna()
                    .to_period(freq))

    return df_resampled

df_dict.update({freq: resample_data(df_daily, freq) for freq in freq_list})
```

```{python}
# Run regressions for every currency and frequency
# Note that statsmodels handles multiple Y's separately

coeffs = []

for freq, data in df_dict.items():

    data_x = sm.add_constant(data['EUR'])
    data_y = data.drop(columns=['EUR'])
    models = sm.OLS(data_y, data_x).fit()
    params = (models.params.T[['EUR']].set_index(data_y.columns)
                .rename(columns={'EUR': freq}))
    coeffs.append(params)

coeffs = pd.concat(coeffs, axis='columns')
coeffs.tail(3)
```

```{python}
coeffs_plot = (coeffs.div(coeffs['D'], axis='rows')
                .drop(columns=['D']))
            
coeffs_plot.plot(kind='density')
coeffs_plot.plot(kind='box')
```

```{python}
covariance = []
varianace = []

for freq, data in df_dict.items():

    data_cov = data.cov()
    cov = data_cov[['EUR']] / data_cov[['EUR']].loc['EUR']
    cov = cov.drop('EUR').rename(columns={'EUR': freq})
    covariance.append(cov)

    var = pd.DataFrame(np.diagonal(data_cov), index=data_cov.index, columns=freq)
    var = var.drop('EUR')
    variance.append(var)
```