[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tiago Souza",
    "section": "",
    "text": "Teste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste\nTeste Teste Teste Teste Teste Teste Teste"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Bayesian Regression - First Assessment",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nimport matplotlib.pyplot as plt\n\n\nreal_estate = pd.read_csv('Real estate.csv')\nreal_estate.head(3)\n\n\n\n\n\n  \n    \n      \n      No\n      X1 transaction date\n      X2 house age\n      X3 distance to the nearest MRT station\n      X4 number of convenience stores\n      X5 latitude\n      X6 longitude\n      Y house price of unit area\n    \n  \n  \n    \n      0\n      1\n      2012.917\n      32.0\n      84.87882\n      10\n      24.98298\n      121.54024\n      37.9\n    \n    \n      1\n      2\n      2012.917\n      19.5\n      306.59470\n      9\n      24.98034\n      121.53951\n      42.2\n    \n    \n      2\n      3\n      2013.583\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      47.3\n    \n  \n\n\n\n\n\nreal_estate.columns = ['transaction_number', 'transaction_date', 'house_age', 'distance_mrt_station', 'convenience_stores', 'latitude', 'longitude', 'price_unit_area']\nreal_estate.set_index('transaction_number', inplace = True)\nreal_estate['intercept'] = 1\nreal_estate.head(3)\n\n\n\n\n\n  \n    \n      \n      transaction_date\n      house_age\n      distance_mrt_station\n      convenience_stores\n      latitude\n      longitude\n      price_unit_area\n      intercept\n    \n    \n      transaction_number\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      2012.917\n      32.0\n      84.87882\n      10\n      24.98298\n      121.54024\n      37.9\n      1\n    \n    \n      2\n      2012.917\n      19.5\n      306.59470\n      9\n      24.98034\n      121.53951\n      42.2\n      1\n    \n    \n      3\n      2013.583\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      47.3\n      1\n    \n  \n\n\n\n\n\nY = real_estate['price_unit_area'].to_numpy().reshape(-1,1)\nX_variables = ['intercept', 'house_age']\nX = real_estate[X_variables].to_numpy().reshape(-1, len(X_variables))\nX[1:5]\n\narray([[ 1. , 19.5],\n       [ 1. , 13.3],\n       [ 1. , 13.3],\n       [ 1. ,  5. ]])\n\n\n\nols_regression = LinearRegression(fit_intercept = False)\nols_regression.fit(X, Y)\nY_pred = ols_regression.predict(X)\n\nplt.scatter(X[:,1], Y)\nplt.plot(X[:,1], Y_pred, color='red')\nplt.xlabel('House Age')\nplt.ylabel('House Price of Unit Area')\nplt.show()\n\n\n\n\n\nalpha_ols, beta_ols = ols_regression.coef_[0]\nprint(alpha_ols, beta_ols)\n\n42.43469704626291 -0.25148841908534514"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesnâ€™t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "DFM\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2022\n\n\nTiago Souza\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neconometrics\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2022\n\n\nTiago Souza\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/fx_decomp/index.html",
    "href": "posts/fx_decomp/index.html",
    "title": "FX Decomposition using Dynamic Factor Models",
    "section": "",
    "text": "This post is to apply a Dynamic Factor Model to uncover common trends in currencies as well as idiosyncratic shocks that some countries might be facing.\n\\[\n\\begin{aligned}\nx^{i}_{t} = \\alpha^{i} + \\sum_{j}{\\beta^{i}_{j} f_{j} + \\varepsilon^{i}_{t}}, \\quad i = 1 \\dots n\n\\end{aligned}\n\\]\n\ndf = eurostat.get_data_df('ert_bil_eur_d', flags=False)\ndf.rename(columns = {'currency\\\\TIME_PERIOD': 'currency'}, inplace = True)\n\nlist_statinfo = ['AVG']\nlist_currency = ['AUD', 'BRL', 'CAD', 'CHF', 'CNY', 'CZK', 'GBP', 'HUF', 'IDR', \\\n     'JPY', 'MXN', 'NZD', 'PLN', 'TRY', 'USD', 'ZAR']\n\ndf = df[(df['statinfo'].isin(list_statinfo)) & \\\n     (df['currency'].isin(list_currency))]\ndf.drop(columns = ['unit', 'statinfo', 'freq'], inplace = True)\n\ndf = pd.melt(df, id_vars = ['currency'], var_name = 'date')\n\ndf['date'] = df['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\ndf.set_index(['date', 'currency'], inplace = True)\n\ndf = df.unstack()\ndf[('value', 'EUR')] = 1\ndf = df.mul(1 / df.loc[:,('value', 'USD')], axis = 0)\ndf.drop('USD', axis = 1, level = 'currency', inplace = True)\nlist_currency.remove('USD')\n\ndf = df.stack()\ndf.reset_index(level = 'currency', inplace = True)\ndf = df.pivot(columns = 'currency', values = 'value')\n#df = df.resample('M').last()\n\ndf.tail()\n\n\n\n\n\n  \n    \n      currency\n      AUD\n      BRL\n      CAD\n      CHF\n      CNY\n      CZK\n      EUR\n      GBP\n      HUF\n      IDR\n      JPY\n      MXN\n      NZD\n      PLN\n      TRY\n      ZAR\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2023-01-05\n      1.463541\n      5.382511\n      1.350439\n      0.928120\n      6.873220\n      22.665786\n      0.943307\n      0.832969\n      374.379775\n      15605.197623\n      132.959155\n      19.376663\n      1.587775\n      4.405245\n      18.770116\n      17.097444\n    \n    \n      2023-01-06\n      1.484762\n      5.336571\n      1.364857\n      0.939429\n      6.861429\n      22.908571\n      0.952381\n      0.842619\n      378.057143\n      15684.095238\n      134.571429\n      19.299524\n      1.608476\n      4.471429\n      18.768095\n      17.342095\n    \n    \n      2023-01-09\n      1.444091\n      5.280011\n      1.336855\n      0.922307\n      6.782536\n      22.428945\n      0.934929\n      0.823186\n      371.400524\n      15577.711294\n      132.152206\n      19.149682\n      1.565165\n      4.390707\n      18.775617\n      17.021223\n    \n    \n      2023-01-10\n      1.456309\n      5.266343\n      1.341229\n      0.923995\n      6.782803\n      22.366875\n      0.932575\n      0.823743\n      372.097361\n      15550.750723\n      132.351021\n      19.145668\n      1.574093\n      4.378439\n      18.777954\n      17.071155\n    \n    \n      2023-01-11\n      1.450451\n      5.195869\n      1.342607\n      0.927422\n      6.774635\n      22.356937\n      0.930492\n      0.825095\n      371.359449\n      15457.653299\n      132.697497\n      19.071090\n      1.573648\n      4.356472\n      18.776682\n      17.011910\n    \n  \n\n\n\n\n\nlist_em = ['BRL', 'CHF', 'CZK', 'HUF', 'IDR', 'MXN', 'PLN', 'TRY', 'ZAR']\n\nlist_dm = list(set(list_currency) - set(list_em))\n\nfactors_mq = {x: ['usd', 'em'] if x in list_em else ['usd', 'dm'] for x in list_currency}\n\n\ndf_est = df.loc['2000-01-01':].copy()\n\nendog_em = df_est[list_em].pct_change()\nendog_dm = df_est[list_dm].pct_change()\n\nplt.plot(endog_em)\nplt.legend()\n\nmodel_em = sm.tsa.DynamicFactor(endog_em, k_factors=1, factor_order=1, error_order=1)\nresult_em = model_em.fit(disp=False)\n\nmodel_dm = sm.tsa.DynamicFactor(endog_dm, k_factors=1, factor_order=1, error_order=1)\nresult_dm = model_dm.fit(disp=False)\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  self._init_dates(dates, freq)\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  self._init_dates(dates, freq)\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\n\n\n\n\ndf_est['factor_em'] = result_em.factors.smoothed[0]\ndf_est['factor_dm'] = result_dm.factors.smoothed[0]\n\nendog_global = df_est[['factor_em', 'factor_dm']]\n\nplt.plot(endog_global)\nplt.legend()\n\nmodel_global = sm.tsa.DynamicFactor(endog_global, k_factors=1, factor_order=1, error_order=1)\nresult_global = model_global.fit(disp=False)\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/tsa/base/tsa_model.py:471: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n  self._init_dates(dates, freq)\n\n\n/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/statsmodels/base/model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n  warnings.warn(\"Maximum Likelihood optimization failed to \"\n\n\n\n\n\n\ndf_est['factor_global'] = result_global.factors.smoothed[0]\n\nplt.plot(df_est['factor_global'])\nplt.legend()\n\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n\n\n<matplotlib.legend.Legend at 0x13ebeb6d0>\n\n\n\n\n\n\n# model = sm.tsa.DynamicFactorMQ(\n#     endog_m, endog_quarterly=endog_q,\n#     factors=factors, factor_orders=factor_orders,\n#     factor_multiplicities=factor_multiplicities)\nprint(df_est[['factor_em', 'factor_dm', 'factor_global']].tail(15))\nfrom scipy.stats import pearsonr\ncorr, _ = pearsonr(df_est['factor_em'], df_est['factor_dm'])\nprint('Pearsons correlation: %.3f' % corr)\n\ncurrency    factor_em  factor_dm  factor_global\ndate                                           \n2022-12-21  -0.059927  -0.081435       0.735832\n2022-12-22  -0.022280   0.005360       0.186527\n2022-12-23  -0.002162   0.017472      -0.014107\n2022-12-27   0.041217  -0.045417      -0.248542\n2022-12-28   0.022716  -0.107312       0.049828\n2022-12-29  -0.069029   0.119988       0.364497\n2022-12-30  -0.017344  -0.126943       0.454206\n2023-01-02  -0.000055   0.011553      -0.005445\n2023-01-03   0.156686   0.176762      -1.906100\n2023-01-04  -0.145457  -0.232314       1.955902\n2023-01-05   0.014978   0.019381      -0.183115\n2023-01-06   0.127845   0.171858      -1.619197\n2023-01-09  -0.202377  -0.372399       2.822352\n2023-01-10  -0.006585   0.084640      -0.153977\n2023-01-11  -0.029203  -0.029067       0.331555\nPearsons correlation: 0.698"
  },
  {
    "objectID": "posts/bayesian_regression/index.html",
    "href": "posts/bayesian_regression/index.html",
    "title": "Bayesian Regression - First Assessment",
    "section": "",
    "text": "This is my first post on Bayesian Econometrics.\n\nreal_estate = pd.read_csv('Real estate.csv')\nreal_estate.head(3)\n\n\n\n\n\n  \n    \n      \n      No\n      X1 transaction date\n      X2 house age\n      X3 distance to the nearest MRT station\n      X4 number of convenience stores\n      X5 latitude\n      X6 longitude\n      Y house price of unit area\n    \n  \n  \n    \n      0\n      1\n      2012.917\n      32.0\n      84.87882\n      10\n      24.98298\n      121.54024\n      37.9\n    \n    \n      1\n      2\n      2012.917\n      19.5\n      306.59470\n      9\n      24.98034\n      121.53951\n      42.2\n    \n    \n      2\n      3\n      2013.583\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      47.3\n    \n  \n\n\n\n\n\nreal_estate.columns = ['transaction_number', 'transaction_date', 'house_age', 'distance_mrt_station', 'convenience_stores', 'latitude', 'longitude', 'price_unit_area']\nreal_estate.set_index('transaction_number', inplace = True)\nreal_estate['intercept'] = 1\nreal_estate.head(3)\n\n\n\n\n\n  \n    \n      \n      transaction_date\n      house_age\n      distance_mrt_station\n      convenience_stores\n      latitude\n      longitude\n      price_unit_area\n      intercept\n    \n    \n      transaction_number\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      2012.917\n      32.0\n      84.87882\n      10\n      24.98298\n      121.54024\n      37.9\n      1\n    \n    \n      2\n      2012.917\n      19.5\n      306.59470\n      9\n      24.98034\n      121.53951\n      42.2\n      1\n    \n    \n      3\n      2013.583\n      13.3\n      561.98450\n      5\n      24.98746\n      121.54391\n      47.3\n      1\n    \n  \n\n\n\n\n\nY = real_estate['price_unit_area'].to_numpy().reshape(-1,1)\nX_variables = ['intercept', 'house_age']\nX = real_estate[X_variables].to_numpy().reshape(-1, len(X_variables))\nX[1:5]\n\narray([[ 1. , 19.5],\n       [ 1. , 13.3],\n       [ 1. , 13.3],\n       [ 1. ,  5. ]])\n\n\n\nols_regression = LinearRegression(fit_intercept = False)\nols_regression.fit(X, Y)\nY_pred = ols_regression.predict(X)\n\nplt.scatter(X[:,1], Y)\nplt.plot(X[:,1], Y_pred, color='red')\nplt.xlabel('House Age')\nplt.ylabel('House Price of Unit Area')\nplt.show()\n\n\n\n\n\nalpha_ols, beta_ols = ols_regression.coef_[0]\nprint(alpha_ols, beta_ols)\n\n42.43469704626291 -0.25148841908534514"
  }
]